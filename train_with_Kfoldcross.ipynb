{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:02.283105Z",
     "start_time": "2024-05-08T14:54:02.278113Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.572702Z",
     "start_time": "2024-05-08T14:54:02.289104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('Data_encoded\\LSTM_data\\combined_data_processed.csv')\n",
    "data.head()"
   ],
   "id": "469a4d8d2f95ae9b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   duration  protocol_type_icmp  protocol_type_tcp  protocol_type_udp  \\\n",
       "0       0.0                 0.0                1.0                0.0   \n",
       "1       0.0                 0.0                0.0                1.0   \n",
       "2       0.0                 0.0                1.0                0.0   \n",
       "3       0.0                 0.0                1.0                0.0   \n",
       "4       0.0                 0.0                1.0                0.0   \n",
       "\n",
       "   service_IRC  service_X11  service_Z39_50  service_aol  service_auth  \\\n",
       "0          0.0          0.0             0.0          0.0           0.0   \n",
       "1          0.0          0.0             0.0          0.0           0.0   \n",
       "2          0.0          0.0             0.0          0.0           0.0   \n",
       "3          0.0          0.0             0.0          0.0           0.0   \n",
       "4          0.0          0.0             0.0          0.0           0.0   \n",
       "\n",
       "   service_bgp  ...  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
       "0          0.0  ...            0.098039                    0.17   \n",
       "1          0.0  ...            0.003922                    0.00   \n",
       "2          0.0  ...            0.101961                    0.10   \n",
       "3          0.0  ...            1.000000                    1.00   \n",
       "4          0.0  ...            1.000000                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.17   \n",
       "1                    0.60                         0.88   \n",
       "2                    0.05                         0.00   \n",
       "3                    0.00                         0.03   \n",
       "4                    0.00                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "\n",
       "    Class  \n",
       "0  Normal  \n",
       "1  Normal  \n",
       "2     DOS  \n",
       "3  Normal  \n",
       "4  Normal  \n",
       "\n",
       "[5 rows x 123 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type_icmp</th>\n",
       "      <th>protocol_type_tcp</th>\n",
       "      <th>protocol_type_udp</th>\n",
       "      <th>service_IRC</th>\n",
       "      <th>service_X11</th>\n",
       "      <th>service_Z39_50</th>\n",
       "      <th>service_aol</th>\n",
       "      <th>service_auth</th>\n",
       "      <th>service_bgp</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>DOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.588104Z",
     "start_time": "2024-05-08T14:54:03.574591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自定义数据集类\n",
    "class CustomDataset(Dataset):\n",
    "    # 类的构造函数。它接受两个参数features和labels，分别表示数据集的特征和标签。\n",
    "    # 在初始化过程中，将这些特征和标签存储在类的实例变量中。\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    # 这是一个特殊方法，用于返回数据集的长度（即数据样本的数量）。\n",
    "    # 在这个方法中，它返回了存储在features中的样本数量，即数据集的长度。\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    # 这也是一个特殊方法，用于根据给定索引idx来获取数据集中的样本。\n",
    "    # 在这个方法中，它根据索引idx从features和labels中获取对应索引的特征和标签，并将它们作为元组返回。\n",
    "    def __getitem__(self, idx):\n",
    "        # return self.features[idx], self.labels[idx]\n",
    "        feature = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 确保 feature 是一个数值型数组\n",
    "        if isinstance(feature, np.ndarray):\n",
    "            if feature.dtype.type is np.str_ or feature.dtype.type is np.object_:\n",
    "                raise ValueError(\"Features must be numeric\")\n",
    "\n",
    "        # 如果 feature 不是一个 ndarray，或者它的 dtype 不是浮点数，尝试将其转换\n",
    "        if not isinstance(feature, np.ndarray) or feature.dtype != 'float32':\n",
    "            feature = np.array(feature, dtype=np.float32)\n",
    "\n",
    "        # 转换为 PyTorch 张量\n",
    "        feature = torch.tensor(feature, dtype=torch.float32)\n",
    "\n",
    "        # 如果标签不是一个张量，转换它\n",
    "        if not torch.is_tensor(label):\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return feature, label"
   ],
   "id": "181e9573f6126cab",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.604099Z",
     "start_time": "2024-05-08T14:54:03.590105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义BiLSTMLayer层模型\n",
    "class BiLSTMLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "        super(BiLSTMLayer, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM的输出包括所有隐藏状态、最后的隐藏状态和最后的细胞状态\n",
    "        output, _ = self.lstm(x)\n",
    "        # 只返回输出张量，不返回隐藏状态和细胞状态\n",
    "        # return output\n",
    "        return output[:, -1, :]  # 只返回最后一个时间步的输出"
   ],
   "id": "697f46add3e0a25b",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.620098Z",
     "start_time": "2024-05-08T14:54:03.606100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义网络结构\n",
    "class CNNBiLSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNBiLSTMModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=122, padding='same')  # 保持输出尺寸不变\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=5)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        # out.shape=(batch=32, channel = 64, seq=24(122池化后的数字))\n",
    "\n",
    "        # input_dim = 就是nn.LSTM(input_size(x的特征维度),hidden_size,...)中的input_size,\n",
    "        # 在该数据中,input_size恒为1\n",
    "\n",
    "        self.bilstm1 = BiLSTMLayer(input_dim=64, hidden_dim=64)  # hidden_size即为上一层的输出channel\n",
    "\n",
    "        # 此处需要将(128, ) reshape为(1,128), 因为要沿着128的方向做池化,\n",
    "        # 为啥要沿128的方向,个人理解128为预测出来的特征,故继续提取特征\n",
    "        self.maxpool1d2 = nn.MaxPool1d(kernel_size=5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(1)\n",
    "\n",
    "        # 第二个BiLSTM\n",
    "        # input=(input_size=1, hidden_size=128, 其他默认) ,seq=25(根据上一层的输出判断的)\n",
    "        self.bilstm2 = BiLSTMLayer(input_dim=1, hidden_dim=128)  # BiLSTM只取了最后一个时间步的输出\n",
    "        # out.shape = (batch=32, 1(啥意思暂不明白), 256(就是128池化后的数字))\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)  # 将上一层随机丢弃一半传入下层\n",
    "        self.fc = nn.Linear(256, 5)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        # shape=(32, 64, 24)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # 重排维度以适配LSTM输入\n",
    "        # shape=(32, 24, 64)\n",
    "\n",
    "        # 第一个BiLSTM\n",
    "        # BiLSTM.output.shape = (batch, seq, hidden_size*2) = (32, 24, 128)\n",
    "        x = self.bilstm1(x)  # 但此处只取了最后一个seq, 此时x.shape=(32,128)\n",
    "        x = x.unsqueeze(1)  # 增加一个维度以适配MaxPool1d\n",
    "        # shape=(32,1,128)\n",
    "\n",
    "        x = self.maxpool1d2(x)  # shape=(32, 1, 25)\n",
    "        x = self.batchnorm2(x)\n",
    "        # out.shape=(32, 1, 25)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # 重排维度以适配LSTM输入\n",
    "        # out.shape=(32, 25, 1)\n",
    "\n",
    "        # 第二个BiLSTM\n",
    "        x = self.bilstm2(x)\n",
    "        # out.shape=(batch=32, 256)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        # x = torch.flatten(x, 1)  # 展平除batch_size外的所有维度, 但是维度已经是(batch, 256)了,没得展了\n",
    "        x = self.fc(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x"
   ],
   "id": "92b1cdd6fec6458a",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.636113Z",
     "start_time": "2024-05-08T14:54:03.621104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# [调试用]打印每一层的输出形状\n",
    "def print_layer_shapes(model, input_tensor):\n",
    "    def hook(module, input, output):\n",
    "        print(f\"{module.__class__.__name__}: {output.shape}\")\n",
    "\n",
    "    # 注册hook\n",
    "    hooks = []\n",
    "    for layer in model.children():\n",
    "        hook_handle = layer.register_forward_hook(hook)\n",
    "        hooks.append(hook_handle)\n",
    "\n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    # 移除hooks\n",
    "    for hook in hooks:\n",
    "        hook.remove()"
   ],
   "id": "1fb6903431361f3c",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.667628Z",
     "start_time": "2024-05-08T14:54:03.637636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 查看模型每一层的输出\n",
    "CNN_LSTM_model = CNNBiLSTMModel()\n",
    "in_tensor = torch.randn(64, 1, 122)  # batch_size=32, in_channels=1, sequence_length=122\n",
    "print_layer_shapes(CNN_LSTM_model, in_tensor)"
   ],
   "id": "f301fdef5606de67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d: torch.Size([64, 64, 122])\n",
      "MaxPool1d: torch.Size([64, 64, 24])\n",
      "BatchNorm1d: torch.Size([64, 64, 24])\n",
      "BiLSTMLayer: torch.Size([64, 128])\n",
      "MaxPool1d: torch.Size([64, 1, 25])\n",
      "BatchNorm1d: torch.Size([64, 1, 25])\n",
      "BiLSTMLayer: torch.Size([64, 256])\n",
      "Dropout: torch.Size([64, 256])\n",
      "Linear: torch.Size([64, 5])\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.683145Z",
     "start_time": "2024-05-08T14:54:03.669631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 检查CUDA\n",
    "def try_device():\n",
    "    if torch.cuda.is_available():\n",
    "        # 选择第一个CUDA设备\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"CUDA is not available. Using CPU instead.\")\n",
    "    return device"
   ],
   "id": "8723eeefa12e27b1",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.699147Z",
     "start_time": "2024-05-08T14:54:03.686148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义数据加载器\n",
    "def loop_data_loder(data_features, data_labels, batch_size):\n",
    "    # 设置features\n",
    "    x_columns = data_features.columns  # 取训练features的全部列名,\n",
    "    x_array = data_features[x_columns].values  # x_array即为本轮循环中,模型的train_features\n",
    "    # x_array.shape = (-1, 122), x_array.class=ndarray\n",
    "\n",
    "    # 重塑features.shape为(-1, c_in=1, seq=122),使其符合网络结构输入\n",
    "    x_features = np.reshape(x_array, (x_array.shape[0], 1, x_array.shape[1]))\n",
    "    # shape=(-1, 1, 122)\n",
    "\n",
    "    # 设置Class\n",
    "    # 如果data_labels已经是一个包含类别名称的Series或者列，你可以这样获取类别索引:\n",
    "    # 假设data_labels是类别名称的Series，你需要将这些名称映射到索引\n",
    "    # 首先获取类别名称到索引的映射字典\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(data_labels.unique())}\n",
    "    # 然后将类别名称转换为索引\n",
    "    y_labels = data_labels.replace(label_to_idx).values\n",
    "    # print(y_labels)\n",
    "    # print(y_labels.dtype)\n",
    "    # train_labels = Index(['DOS', 'Probe', 'R2L', 'U2R', 'normal'], dtype='object')\n",
    "    # train_labels.shape = (-1,5)\n",
    "\n",
    "    # 创建数据集和数据加载器\n",
    "    dataset = CustomDataset(x_features, y_labels)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return data_loader"
   ],
   "id": "3c9ff099941d865a",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.715146Z",
     "start_time": "2024-05-08T14:54:03.701149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设定超参数\n",
    "learning_rate = 0.01\n",
    "numb_epochs = 10\n",
    "batch_size = 64\n",
    "weight_decay = 0.05\n",
    "device = try_device()"
   ],
   "id": "1ab68d8778051df3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.731155Z",
     "start_time": "2024-05-08T14:54:03.718147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 分层K折\n",
    "num_folds = 6\n",
    "k_fold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)  # 随机种子固定,保证每次生成的都一样"
   ],
   "id": "6928fedfff3546d5",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.746665Z",
     "start_time": "2024-05-08T14:54:03.733153Z"
    }
   },
   "cell_type": "code",
   "source": "k_fold",
   "id": "22a2e4525dc134d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=6, random_state=42, shuffle=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.762663Z",
     "start_time": "2024-05-08T14:54:03.748663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)"
   ],
   "id": "5b199bfa1f7313c3",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.778763Z",
     "start_time": "2024-05-08T14:54:03.763664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 评估accuracy\n",
    "def evaluate_accuracy(net, data_loader, device):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = net(X)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ],
   "id": "3d64f2be68c1b17a",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.810182Z",
     "start_time": "2024-05-08T14:54:03.780664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 实例化模型\n",
    "model = CNNBiLSTMModel()\n",
    "\n",
    "# 初始化模型参数\n",
    "model.apply(init_weights)\n",
    "\n",
    "# 模型传入device\n",
    "print('Training on', device)\n",
    "model.to(device)\n",
    "\n",
    "# 设置优化器和损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "oos_pred = []  # 用于存储每个验证集的准确率\n",
    "\n",
    "# todo 检查是否还有其他需要初始化的\n"
   ],
   "id": "1e734ea70efc4b65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:03.889220Z",
     "start_time": "2024-05-08T14:54:03.812184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = data.copy()    # 不改变源数据\n",
    "print(data.shape)\n",
    "print(train_data.shape)\n",
    "# 下面两项操作都不会改变train_data数据,在模型中不需要改变\n",
    "labels = train_data['Class']\n",
    "print(labels.shape)\n",
    "print(train_data.shape)\n",
    "features  = train_data.drop(['Class'], axis=1, inplace=False)\n",
    "print(features.shape)"
   ],
   "id": "ed01039e1d59ef1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148517, 123)\n",
      "(148517, 123)\n",
      "(148517,)\n",
      "(148517, 123)\n",
      "(148517, 122)\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T15:09:11.958147Z",
     "start_time": "2024-05-08T14:54:03.891221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# todo 完善训练模型\n",
    "for epoch in range(numb_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{numb_epochs}')\n",
    "    # 全部K折完算一次epoch, 共需要经历numb_epochs次迭代\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    fold = 0\n",
    "    for (train_index, val_index) in k_fold.split(features, labels):\n",
    "        fold += 1\n",
    "        print(f'Fold {fold}/{num_folds}')   # 当前为第fold次K折\n",
    "        # 根据K折设置训练集和验证集\n",
    "        train_data, val_data = features.iloc[train_index], features.iloc[val_index]\n",
    "        train_labels, val_labels = labels.iloc[train_index], labels.iloc[val_index]\n",
    "        # print(train_data.shape, val_data.shape)\n",
    "        # print(train_labels.shape, val_labels.shape)\n",
    "        \n",
    "        # 设置data_loder\n",
    "        # loop_data_loder(data_features, data_labels, batch_size)\n",
    "        train_loder = loop_data_loder(train_data, train_labels, batch_size)\n",
    "        val_loder = loop_data_loder(val_data, val_labels, batch_size)\n",
    "        # 在data_loder后将数据传到device\n",
    "\n",
    "        # todo 在训练集上训练模型\n",
    "        model.train()\n",
    "        for train_batch, train_label_batch in train_loder:\n",
    "            optimizer.zero_grad()\n",
    "            train_batch, train_label_batch = train_batch.to(device), train_label_batch.to(device)\n",
    "            train_batch = train_batch.float()  # 确保输入数据类型为FloatTensor\n",
    "            train_label_batch = train_label_batch.long()  # 将目标张量转换为长整型\n",
    "            \n",
    "            y_hat = model(train_batch)\n",
    "            # print(y_hat)\n",
    "            loss = loss_fn(y_hat, train_label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, train_pred = torch.max(y_hat, 1)\n",
    "            total += train_label_batch.size(0)\n",
    "            correct += (train_pred == train_label_batch).sum().item()\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss = train_loss / len(train_loder)\n",
    "\n",
    "        # todo 在验证集上评估模型\n",
    "        model.eval()\n",
    "        val_total = 0\n",
    "        val_correct = 0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_batch, val_label_batch in val_loder:\n",
    "                val_batch, val_label_batch = val_batch.to(device), val_label_batch.to(device)\n",
    "                val_batch = val_batch.float()  # 确保输入数据类型为FloatTensor\n",
    "                # val_label_batch = val_label_batch.long()    # 将目标张量转换为长整型\n",
    "                y_val = model(val_batch)\n",
    "                \n",
    "\n",
    "                loss_val = loss_fn(y_val, val_label_batch)\n",
    "                val_loss += loss_val.item()\n",
    "                _, val_pred = torch.max(y_val, 1)\n",
    "                val_total += val_label_batch.size(0)\n",
    "                val_correct += (val_pred == val_label_batch).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss = val_loss / len(val_loder)\n",
    "\n",
    "        print(f'Training Loss: {train_loss}, Training Accuracy: {train_accuracy}')\n",
    "        print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "    print('--------------------------------------')"
   ],
   "id": "3666512fce644da8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Fold 1/6\n",
      "Training Loss: 0.32583088131145704, Training Accuracy: 0.9226754144985618\n",
      "Validation Loss: 3.1408667071537146, Validation Accuracy: 0.029491374782854605\n",
      "Fold 2/6\n",
      "Training Loss: 0.31194368914201914, Training Accuracy: 0.9246792282085259\n",
      "Validation Loss: 0.3230449287389292, Validation Accuracy: 0.9282915202197713\n",
      "Fold 3/6\n",
      "Training Loss: 0.32685274381233137, Training Accuracy: 0.9248085065123945\n",
      "Validation Loss: 0.5417083008960852, Validation Accuracy: 0.843816911081485\n",
      "Fold 4/6\n",
      "Training Loss: 0.3325381259369977, Training Accuracy: 0.9250246436766749\n",
      "Validation Loss: 4.137502382584012, Validation Accuracy: 0.026703833878721772\n",
      "Fold 5/6\n",
      "Training Loss: 0.3283541427092591, Training Accuracy: 0.9254128825829805\n",
      "Validation Loss: 4.297146988777535, Validation Accuracy: 0.033288894275441364\n",
      "Fold 6/6\n",
      "Training Loss: 0.3257765591206733, Training Accuracy: 0.925710861382872\n",
      "Validation Loss: 0.503890749981545, Validation Accuracy: 0.8467598577892695\n",
      "--------------------------------------\n",
      "Epoch 2/10\n",
      "Fold 1/6\n",
      "Training Loss: 0.32950332404076743, Training Accuracy: 0.9261901683849908\n",
      "Validation Loss: 4.654086737669716, Validation Accuracy: 0.025532258716115218\n",
      "Fold 2/6\n",
      "Training Loss: 0.3285767837238642, Training Accuracy: 0.9262265279079539\n",
      "Validation Loss: 0.33896533313185667, Validation Accuracy: 0.9294630953823779\n",
      "Fold 3/6\n",
      "Training Loss: 0.32830185478368246, Training Accuracy: 0.9263302198808485\n",
      "Validation Loss: 0.4673229576466311, Validation Accuracy: 0.8496343877509797\n",
      "Fold 4/6\n",
      "Training Loss: 0.3320464971973123, Training Accuracy: 0.9263093468213697\n",
      "Validation Loss: 4.632878361438288, Validation Accuracy: 0.023552700682745526\n",
      "Fold 5/6\n",
      "Training Loss: 0.33167203276318635, Training Accuracy: 0.9260867457418959\n",
      "Validation Loss: 3.6916231141841997, Validation Accuracy: 0.04298468872459904\n",
      "Fold 6/6\n",
      "Training Loss: 0.33393799448733946, Training Accuracy: 0.9258401395126484\n",
      "Validation Loss: 0.4483996305508823, Validation Accuracy: 0.8548400129282482\n",
      "--------------------------------------\n",
      "Epoch 3/10\n",
      "Fold 1/6\n",
      "Training Loss: 0.3303573636305369, Training Accuracy: 0.9265376038266377\n",
      "Validation Loss: 4.533691060019402, Validation Accuracy: 0.02634024158687836\n",
      "Fold 2/6\n",
      "Training Loss: 0.3301657953222517, Training Accuracy: 0.9261538088620277\n",
      "Validation Loss: 0.30442619572083157, Validation Accuracy: 0.932331434573587\n",
      "Fold 3/6\n",
      "Training Loss: 0.3297057654262185, Training Accuracy: 0.926365232754813\n",
      "Validation Loss: 0.4457393424917561, Validation Accuracy: 0.8538762978224862\n",
      "Fold 4/6\n",
      "Training Loss: 0.3302063085668275, Training Accuracy: 0.9262750072719046\n",
      "Validation Loss: 5.420348821684372, Validation Accuracy: 0.02791580818486648\n",
      "Fold 5/6\n",
      "Training Loss: 0.32897932470548696, Training Accuracy: 0.9261691606606122\n",
      "Validation Loss: 5.581943324678012, Validation Accuracy: 0.024643477558275763\n",
      "Fold 6/6\n",
      "Training Loss: 0.3291572007643251, Training Accuracy: 0.92624682696257\n",
      "Validation Loss: 0.5109525820389582, Validation Accuracy: 0.845467032967033\n",
      "--------------------------------------\n",
      "Epoch 4/10\n",
      "Fold 1/6\n",
      "Training Loss: 0.33166005206222127, Training Accuracy: 0.9264002456287773\n",
      "Validation Loss: 4.125441309093505, Validation Accuracy: 0.032036520825758495\n",
      "Fold 2/6\n",
      "Training Loss: 0.32822877967514874, Training Accuracy: 0.9260366503991467\n",
      "Validation Loss: 0.35562630090140557, Validation Accuracy: 0.9276047347796227\n",
      "Fold 3/6\n",
      "Training Loss: 0.33472722441740915, Training Accuracy: 0.9251317022720662\n",
      "Validation Loss: 0.49636971009101055, Validation Accuracy: 0.851007958631277\n",
      "Fold 4/6\n",
      "Training Loss: 0.33194640368793754, Training Accuracy: 0.9252003813709964\n",
      "Validation Loss: 3.5573436622471775, Validation Accuracy: 0.028239001333171736\n",
      "Fold 5/6\n",
      "Training Loss: 0.3334419063326952, Training Accuracy: 0.925008887883391\n",
      "Validation Loss: 4.604273846599175, Validation Accuracy: 0.030420555084232213\n",
      "Fold 6/6\n",
      "Training Loss: 0.33098946687064457, Training Accuracy: 0.9250281112599904\n",
      "Validation Loss: 0.4621308343509063, Validation Accuracy: 0.8535067873303167\n",
      "--------------------------------------\n",
      "Epoch 5/10\n",
      "Fold 1/6\n",
      "Training Loss: 0.333187290395089, Training Accuracy: 0.9234430044277819\n",
      "Validation Loss: 4.298408190409343, Validation Accuracy: 0.021249949501070578\n",
      "Fold 2/6\n",
      "Training Loss: 0.3338641377002775, Training Accuracy: 0.9239762774312401\n",
      "Validation Loss: 0.33209320259802716, Validation Accuracy: 0.9291399022340726\n",
      "Fold 3/6\n",
      "Training Loss: 0.33584591374965744, Training Accuracy: 0.9237958264654235\n",
      "Validation Loss: 0.48675885280589415, Validation Accuracy: 0.8439381085120995\n",
      "Fold 4/6\n",
      "Training Loss: 0.3329936921993386, Training Accuracy: 0.9240368766361785\n",
      "Validation Loss: 4.469729148756318, Validation Accuracy: 0.028400597907324365\n",
      "Fold 5/6\n",
      "Training Loss: 0.3344569052172011, Training Accuracy: 0.9240134449436024\n",
      "Validation Loss: 4.699265831200651, Validation Accuracy: 0.028683391912091464\n",
      "Fold 6/6\n",
      "Training Loss: 0.33508166048607263, Training Accuracy: 0.9239494468646687\n",
      "Validation Loss: 0.5273029699883104, Validation Accuracy: 0.8497091144149967\n",
      "--------------------------------------\n",
      "Epoch 6/10\n",
      "Fold 1/6\n",
      "Training Loss: 0.33462608398748284, Training Accuracy: 0.9236450017775767\n",
      "Validation Loss: 4.689053212641437, Validation Accuracy: 0.023189108390902113\n",
      "Fold 2/6\n",
      "Training Loss: 0.33244395004372473, Training Accuracy: 0.9238550790213632\n",
      "Validation Loss: 0.35826276219630426, Validation Accuracy: 0.9200500949379873\n",
      "Fold 3/6\n",
      "Training Loss: 0.33425248865266305, Training Accuracy: 0.9239708908352455\n",
      "Validation Loss: 0.46571121586231606, Validation Accuracy: 0.8508463620571244\n",
      "Fold 4/6\n",
      "Training Loss: 0.33381940262488596, Training Accuracy: 0.9239702175107463\n",
      "Validation Loss: 4.853267684463383, Validation Accuracy: 0.02432028440997051\n",
      "Fold 5/6\n",
      "Training Loss: 0.33449813815168006, Training Accuracy: 0.9239762774312401\n",
      "Validation Loss: 4.365608876989794, Validation Accuracy: 0.024077889548741568\n",
      "Fold 6/6\n",
      "Training Loss: 0.3344696019824242, Training Accuracy: 0.9239709932196314\n",
      "Validation Loss: 0.471643102762003, Validation Accuracy: 0.8509211376858435\n",
      "--------------------------------------\n",
      "Epoch 7/10\n",
      "Fold 1/6\n",
      "Training Loss: 0.333142803328915, Training Accuracy: 0.9239277980672893\n",
      "Validation Loss: 4.61622093814288, Validation Accuracy: 0.023956692118127097\n",
      "Fold 2/6\n",
      "Training Loss: 0.33137800339999385, Training Accuracy: 0.9241257554700882\n",
      "Validation Loss: 0.3224685963349133, Validation Accuracy: 0.9248171938754899\n",
      "Fold 3/6\n",
      "Training Loss: 0.3354388698616741, Training Accuracy: 0.9237715867834481\n",
      "Validation Loss: 0.4792092347021867, Validation Accuracy: 0.8534319072435664\n",
      "Fold 4/6\n",
      "Training Loss: 0.3352670491997454, Training Accuracy: 0.9236975210885233\n",
      "Validation Loss: 3.775412390706459, Validation Accuracy: 0.03155173110330061\n",
      "Fold 5/6\n",
      "Training Loss: 0.3325102598908801, Training Accuracy: 0.9237435764842765\n",
      "Validation Loss: 4.347422246169058, Validation Accuracy: 0.024077889548741568\n",
      "Fold 6/6\n",
      "Training Loss: 0.33165581959163654, Training Accuracy: 0.923880767858225\n",
      "Validation Loss: 0.4927408880041551, Validation Accuracy: 0.8477698771816419\n",
      "--------------------------------------\n",
      "Epoch 8/10\n",
      "Fold 1/6\n",
      "Training Loss: 0.33159317927591064, Training Accuracy: 0.9244853107527229\n",
      "Validation Loss: 4.809514783765611, Validation Accuracy: 0.02322950753444027\n",
      "Fold 2/6\n",
      "Training Loss: 0.33141680883593366, Training Accuracy: 0.9242469538799651\n",
      "Validation Loss: 0.3323394955359688, Validation Accuracy: 0.932573829434816\n",
      "Fold 3/6\n",
      "Training Loss: 0.33224586901345665, Training Accuracy: 0.9242321407409801\n",
      "Validation Loss: 0.46234589892148353, Validation Accuracy: 0.8518563406455784\n",
      "Fold 4/6\n",
      "Training Loss: 0.3322490652762175, Training Accuracy: 0.9242590737209527\n",
      "Validation Loss: 4.231769282688466, Validation Accuracy: 0.027875409041328323\n",
      "Fold 5/6\n",
      "Training Loss: 0.33264495515847825, Training Accuracy: 0.9241071717139071\n",
      "Validation Loss: 4.8324894510806375, Validation Accuracy: 0.027754211610713852\n",
      "Fold 6/6\n",
      "Training Loss: 0.3323608460727745, Training Accuracy: 0.9240531386979268\n",
      "Validation Loss: 0.4816730107139863, Validation Accuracy: 0.8499111182934712\n",
      "--------------------------------------\n",
      "Epoch 9/10\n",
      "Fold 1/6\n",
      "Training Loss: 0.32994371928821675, Training Accuracy: 0.9250428234381565\n",
      "Validation Loss: 4.335632275549324, Validation Accuracy: 0.028804589342705935\n",
      "Fold 2/6\n",
      "Training Loss: 0.32974380492197386, Training Accuracy: 0.9249216250282797\n",
      "Validation Loss: 0.3412662224329103, Validation Accuracy: 0.924857593019028\n",
      "Fold 3/6\n",
      "Training Loss: 0.33274341700287974, Training Accuracy: 0.9247977333204055\n",
      "Validation Loss: 0.45586156259827526, Validation Accuracy: 0.8516947440714256\n",
      "Fold 4/6\n",
      "Training Loss: 0.3333720855524164, Training Accuracy: 0.9247337674929705\n",
      "Validation Loss: 3.5121512758023363, Validation Accuracy: 0.03139013452914798\n",
      "Fold 5/6\n",
      "Training Loss: 0.3321972443624971, Training Accuracy: 0.9245451019682622\n",
      "Validation Loss: 4.581598202387492, Validation Accuracy: 0.026946228739950714\n",
      "Fold 6/6\n",
      "Training Loss: 0.3332718316838769, Training Accuracy: 0.9242618690116283\n",
      "Validation Loss: 0.5128550579535561, Validation Accuracy: 0.8534663865546218\n",
      "--------------------------------------\n",
      "Epoch 10/10\n",
      "Fold 1/6\n",
      "Training Loss: 0.3320082811775474, Training Accuracy: 0.9244933906467148\n",
      "Validation Loss: 4.282360474268596, Validation Accuracy: 0.023552700682745526\n",
      "Fold 2/6\n",
      "Training Loss: 0.3303516487238543, Training Accuracy: 0.9248448660353576\n",
      "Validation Loss: 0.36385934297428574, Validation Accuracy: 0.9126974508140427\n",
      "Fold 3/6\n",
      "Training Loss: 0.3328033086044711, Training Accuracy: 0.9245257102226819\n",
      "Validation Loss: 0.47697402186479987, Validation Accuracy: 0.8482608168706823\n",
      "Fold 4/6\n",
      "Training Loss: 0.3309240637320204, Training Accuracy: 0.9245055104877024\n",
      "Validation Loss: 4.651652935555431, Validation Accuracy: 0.025976649295034945\n",
      "Fold 5/6\n",
      "Training Loss: 0.3340162873274855, Training Accuracy: 0.924233218060179\n",
      "Validation Loss: 4.904416035004056, Validation Accuracy: 0.022704318668444228\n",
      "Fold 6/6\n",
      "Training Loss: 0.3338559363565133, Training Accuracy: 0.9242308961263693\n",
      "Validation Loss: 0.45404965424722477, Validation Accuracy: 0.8543552036199095\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T15:09:11.965520Z",
     "start_time": "2024-05-08T15:09:11.959148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# [测试]前向传播过程是否正常\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设有 3 个类别\n",
    "num_classes = 3\n",
    "batch_size = 5\n",
    "\n",
    "# 创建一个简单的模型\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, num_classes)\n",
    ")\n",
    "\n",
    "# 定义损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 随机生成一些输入和标签\n",
    "inputs = torch.randn(batch_size, 10)\n",
    "targets = torch.randint(0, num_classes, (batch_size,))\n",
    "\n",
    "# 前向传播\n",
    "outputs = model(inputs)\n",
    "\n",
    "# 计算损失\n",
    "loss = loss_fn(outputs, targets)\n",
    "\n",
    "print(loss)\n"
   ],
   "id": "7fb4be6e3b3c6ad6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0117, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "execution_count": 72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
