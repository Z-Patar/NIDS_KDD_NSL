{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:35.101267Z",
     "start_time": "2024-05-10T07:34:33.266388Z"
    }
   },
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import optuna\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:35.116790Z",
     "start_time": "2024-05-10T07:34:35.102268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # [测试]前向传播过程是否正常\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# \n",
    "# # 假设有 3 个类别\n",
    "# num_classes = 3\n",
    "# batch_size = 5\n",
    "# \n",
    "# # 创建一个简单的模型\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(10, num_classes)\n",
    "# )\n",
    "# \n",
    "# # 定义损失函数\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# \n",
    "# # 随机生成一些输入和标签\n",
    "# inputs = torch.randn(batch_size, 10)\n",
    "# targets = torch.randint(0, num_classes, (batch_size,))\n",
    "# \n",
    "# # 前向传播\n",
    "# outputs = model(inputs)\n",
    "# \n",
    "# # 计算损失\n",
    "# loss = loss_fn(outputs, targets)\n",
    "# \n",
    "# print(loss)\n"
   ],
   "id": "c31b2973aa60f2d8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.023317Z",
     "start_time": "2024-05-10T07:34:35.117789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('Data_encoded\\LSTM_data\\combined_data_processed.csv')\n",
    "data.head()"
   ],
   "id": "469a4d8d2f95ae9b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   duration  protocol_type_icmp  protocol_type_tcp  protocol_type_udp  \\\n",
       "0       0.0                 0.0                1.0                0.0   \n",
       "1       0.0                 0.0                0.0                1.0   \n",
       "2       0.0                 0.0                1.0                0.0   \n",
       "3       0.0                 0.0                1.0                0.0   \n",
       "4       0.0                 0.0                1.0                0.0   \n",
       "\n",
       "   service_IRC  service_X11  service_Z39_50  service_aol  service_auth  \\\n",
       "0          0.0          0.0             0.0          0.0           0.0   \n",
       "1          0.0          0.0             0.0          0.0           0.0   \n",
       "2          0.0          0.0             0.0          0.0           0.0   \n",
       "3          0.0          0.0             0.0          0.0           0.0   \n",
       "4          0.0          0.0             0.0          0.0           0.0   \n",
       "\n",
       "   service_bgp  ...  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
       "0          0.0  ...            0.098039                    0.17   \n",
       "1          0.0  ...            0.003922                    0.00   \n",
       "2          0.0  ...            0.101961                    0.10   \n",
       "3          0.0  ...            1.000000                    1.00   \n",
       "4          0.0  ...            1.000000                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.17   \n",
       "1                    0.60                         0.88   \n",
       "2                    0.05                         0.00   \n",
       "3                    0.00                         0.03   \n",
       "4                    0.00                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "\n",
       "    Class  \n",
       "0  Normal  \n",
       "1  Normal  \n",
       "2     Dos  \n",
       "3  Normal  \n",
       "4  Normal  \n",
       "\n",
       "[5 rows x 123 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type_icmp</th>\n",
       "      <th>protocol_type_tcp</th>\n",
       "      <th>protocol_type_udp</th>\n",
       "      <th>service_IRC</th>\n",
       "      <th>service_X11</th>\n",
       "      <th>service_Z39_50</th>\n",
       "      <th>service_aol</th>\n",
       "      <th>service_auth</th>\n",
       "      <th>service_bgp</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.039343Z",
     "start_time": "2024-05-10T07:34:36.024317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自定义数据集类\n",
    "class CustomDataset(Dataset):\n",
    "    # 类的构造函数。它接受两个参数features和labels，分别表示数据集的特征和标签。\n",
    "    # 在初始化过程中，将这些特征和标签存储在类的实例变量中。\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    # 这是一个特殊方法，用于返回数据集的长度（即数据样本的数量）。\n",
    "    # 在这个方法中，它返回了存储在features中的样本数量，即数据集的长度。\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    # 这也是一个特殊方法，用于根据给定索引idx来获取数据集中的样本。\n",
    "    # 在这个方法中，它根据索引idx从features和labels中获取对应索引的特征和标签，并将它们作为元组返回。\n",
    "    def __getitem__(self, idx):\n",
    "        # return self.features[idx], self.labels[idx]\n",
    "        feature = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 确保 feature 是一个数值型数组\n",
    "        if isinstance(feature, np.ndarray):\n",
    "            if feature.dtype.type is np.str_ or feature.dtype.type is np.object_:\n",
    "                raise ValueError(\"Features must be numeric\")\n",
    "\n",
    "        # 如果 feature 不是一个 ndarray，或者它的 dtype 不是浮点数，尝试将其转换\n",
    "        if not isinstance(feature, np.ndarray) or feature.dtype != 'float32':\n",
    "            feature = np.array(feature, dtype=np.float32)\n",
    "\n",
    "        # 转换为 PyTorch 张量\n",
    "        feature = torch.tensor(feature, dtype=torch.float32)\n",
    "\n",
    "        # 如果标签不是一个张量，转换它\n",
    "        if not torch.is_tensor(label):\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return feature, label"
   ],
   "id": "181e9573f6126cab",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.054490Z",
     "start_time": "2024-05-10T07:34:36.041345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义BiLSTMLayer层模型\n",
    "class BiLSTMLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "        super(BiLSTMLayer, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM的输出包括所有隐藏状态、最后的隐藏状态和最后的细胞状态\n",
    "        output, _ = self.lstm(x)\n",
    "        # 只返回输出张量，不返回隐藏状态和细胞状态\n",
    "        return output[:, -1, :]  # 只返回最后一个时间步的输出"
   ],
   "id": "697f46add3e0a25b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.070618Z",
     "start_time": "2024-05-10T07:34:36.055491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义网络结构\n",
    "class CNNBiLSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNBiLSTMModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=122, padding='same')  # 保持输出尺寸不变\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=5)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        # out.shape=(batch=32, channel = 64, seq=24(122池化后的数字))\n",
    "\n",
    "        # input_dim = 就是nn.LSTM(input_size(x的特征维度),hidden_size,...)中的input_size,\n",
    "        # 在该数据中,input_size恒为1\n",
    "\n",
    "        self.bilstm1 = BiLSTMLayer(input_dim=64, hidden_dim=64)  # hidden_size即为上一层的输出channel\n",
    "\n",
    "        # 此处需要将(128, ) reshape为(1,128), 因为要沿着128的方向做池化,\n",
    "        # 为啥要沿128的方向,个人理解128为预测出来的特征,故继续提取特征\n",
    "        self.maxpool1d2 = nn.MaxPool1d(kernel_size=5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(1)\n",
    "\n",
    "        # 第二个BiLSTM\n",
    "        # input=(input_size=1, hidden_size=128, 其他默认) ,seq=25(根据上一层的输出判断的)\n",
    "        self.bilstm2 = BiLSTMLayer(input_dim=1, hidden_dim=128)  # BiLSTM只取了最后一个时间步的输出\n",
    "        # out.shape = (batch=32, 1(啥意思暂不明白), 256(就是128池化后的数字))\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)  # 将上一层随机丢弃一半传入下层\n",
    "        self.fc = nn.Linear(256, 5)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        # shape=(32, 64, 24)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # 重排维度以适配LSTM输入\n",
    "        # shape=(32, 24, 64)\n",
    "\n",
    "        # 第一个BiLSTM\n",
    "        # BiLSTM.output.shape = (batch, seq, hidden_size*2) = (32, 24, 128)\n",
    "        x = self.bilstm1(x)  # 但此处只取了最后一个seq, 此时x.shape=(32,128)\n",
    "        x = x.unsqueeze(1)  # 增加一个维度以适配MaxPool1d\n",
    "        # shape=(32,1,128)\n",
    "\n",
    "        x = self.maxpool1d2(x)  # shape=(32, 1, 25)\n",
    "        x = self.batchnorm2(x)\n",
    "        # out.shape=(32, 1, 25)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # 重排维度以适配LSTM输入\n",
    "        # out.shape=(32, 25, 1)\n",
    "\n",
    "        # 第二个BiLSTM\n",
    "        x = self.bilstm2(x)\n",
    "        # out.shape=(batch=32, 256)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        # x = torch.flatten(x, 1)  # 展平除batch_size外的所有维度, 但是维度已经是(batch, 256)了,没得展了\n",
    "        x = self.fc(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x"
   ],
   "id": "92b1cdd6fec6458a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.086038Z",
     "start_time": "2024-05-10T07:34:36.071515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from torchsummary import summary\n",
    "# net = CNNBiLSTMModel()\n",
    "# net.to('cpu')  # 确保模型在cpu\n",
    "# x = torch.rand(32,1,122).to('cpu')\n",
    "# summary(net,input_size=(1,122), batch_size=32, device='cpu')\n"
   ],
   "id": "1787d3a349dad4a6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.118535Z",
     "start_time": "2024-05-10T07:34:36.103422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# [调试用]打印每一层的输出形状\n",
    "def print_layer_shapes(model, input_tensor):\n",
    "    def hook(module, input, output):\n",
    "        # 这里检查输出是否是元组，如果是的话，我们只打印第一个元素的形状\n",
    "        if isinstance(output, tuple):\n",
    "            print(f\"{module.__class__.__name__}: {output[0].shape}\")\n",
    "        else:\n",
    "            print(f\"{module.__class__.__name__}: {output.shape}\")\n",
    "    \n",
    "    # 注册hook\n",
    "    hooks = []\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.ModuleList):\n",
    "            for sublayer in layer.children():\n",
    "                hook_handle = sublayer.register_forward_hook(hook)\n",
    "                hooks.append(hook_handle)\n",
    "        else:\n",
    "            hook_handle = layer.register_forward_hook(hook)\n",
    "            hooks.append(hook_handle)\n",
    "\n",
    "\n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    # 移除hooks\n",
    "    for hook in hooks:\n",
    "        hook.remove()"
   ],
   "id": "1fb6903431361f3c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.165618Z",
     "start_time": "2024-05-10T07:34:36.121538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# [调试用]查看模型每一层的输出\n",
    "CNN_LSTM_model = CNNBiLSTMModel()\n",
    "in_tensor = torch.randn(64, 1, 122)  # batch_size=32, in_channels=1, sequence_length=122\n",
    "print_layer_shapes(CNN_LSTM_model, in_tensor)"
   ],
   "id": "f301fdef5606de67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d: torch.Size([64, 64, 122])\n",
      "MaxPool1d: torch.Size([64, 64, 24])\n",
      "BatchNorm1d: torch.Size([64, 64, 24])\n",
      "BiLSTMLayer: torch.Size([64, 128])\n",
      "MaxPool1d: torch.Size([64, 1, 25])\n",
      "BatchNorm1d: torch.Size([64, 1, 25])\n",
      "BiLSTMLayer: torch.Size([64, 256])\n",
      "Dropout: torch.Size([64, 256])\n",
      "Linear: torch.Size([64, 5])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.181260Z",
     "start_time": "2024-05-10T07:34:36.166622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 检查CUDA\n",
    "def try_device():\n",
    "    if torch.cuda.is_available():\n",
    "        # 选择第一个CUDA设备\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"CUDA is not available. Using CPU instead.\")\n",
    "    return device"
   ],
   "id": "8723eeefa12e27b1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.197300Z",
     "start_time": "2024-05-10T07:34:36.182262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义数据加载器\n",
    "def loop_data_loder(data_features, data_labels, batch_size):\n",
    "    # 设置features\n",
    "    x_columns = data_features.columns  # 取训练features的全部列名,\n",
    "    x_array = data_features[x_columns].values  # x_array即为本轮循环中,模型的train_features\n",
    "    # x_array.shape = (-1, 122), x_array.class=ndarray\n",
    "\n",
    "    # 重塑features.shape为(-1, c_in=1, seq=122),使其符合网络结构输入\n",
    "    x_features = np.reshape(x_array, (x_array.shape[0], 1, x_array.shape[1]))\n",
    "    # shape=(-1, 1, 122)\n",
    "\n",
    "    # 设置Class\n",
    "    # 如果data_labels已经是一个包含类别名称的Series或者列，你可以这样获取类别索引:\n",
    "    # 假设data_labels是类别名称的Series，你需要将这些名称映射到索引\n",
    "    # 首先获取类别名称到索引的映射字典\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(data_labels.unique())}\n",
    "    # 然后将类别名称转换为索引\n",
    "    y_labels = data_labels.replace(label_to_idx).values\n",
    "    # print(y_labels)\n",
    "    # print(y_labels.dtype)\n",
    "    # train_labels = Index(['DOS', 'Probe', 'R2L', 'U2R', 'normal'], dtype='object')\n",
    "    # train_labels.shape = (-1,5)\n",
    "\n",
    "    # 创建数据集和数据加载器\n",
    "    dataset = CustomDataset(x_features, y_labels)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return data_loader"
   ],
   "id": "3c9ff099941d865a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.244904Z",
     "start_time": "2024-05-10T07:34:36.198807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设置随机种子\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# 如果你使用的是cuDNN，还可以设置以下选项来进一步确保确定性\n",
    "# 确保算法的确定性，即使这可能会牺牲一些性能。\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# 禁用cuDNN的自动性能优化（自动寻找最适合当前配置的卷积算法），因为这些优化可能会导致计算结果的不确定性。\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 模型参数初始化函数\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv1d):    # 一维卷积层\n",
    "        nn.init.xavier_uniform_(m.weight)   # weight用了Xavier均匀初始化\n",
    "        if m.bias is not None:      # bias存在时，初始化为0\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.LSTM):    # 对于LSTM层\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:     # 输入到隐藏层的权重weight_ih\n",
    "                nn.init.xavier_uniform_(param.data) # 使用了Xavier均匀初始化\n",
    "                \n",
    "            elif 'weight_hh' in name:   # 隐藏层到隐藏层的权重weight_hh，\n",
    "                # 正交初始化通常用于循环神经网络的隐藏层权重，因为它可以帮助维持梯度的规模，从而在训练过程中防止梯度消失或爆炸。\n",
    "                # todo 测试随机正态分布初始化后的结果是否优于正交初始化\n",
    "                nn.init.orthogonal_(param.data)     # 正交初始化\n",
    "                # nn.init.xavier_uniform_(param.data)     # 随机正态分布初始化\n",
    "                \n",
    "            elif 'bias' in name:    # 对于LSTM层的偏置项，\n",
    "                param.data.fill_(0)     #   先所有偏置项初始化为0\n",
    "                # todo 测试偏置全为0的结果好，还是遗忘门偏置为1的结果好\n",
    "                n = param.size(0)\n",
    "                start, end = n // 4, n // 2\n",
    "                param.data[start:end].fill_(1.) # 然后将遗忘门偏置初始化为1，这在某些情况下可以帮助模型记忆顺序，提高学习能力。\n",
    "    elif isinstance(m, nn.Linear):  # 线性层使用了Xavier均匀初始化\n",
    "        nn.init.xavier_uniform_(m.weight)   \n",
    "        nn.init.constant_(m.bias, 0)    "
   ],
   "id": "9f08df48b8e93073",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.260307Z",
     "start_time": "2024-05-10T07:34:36.245906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设定超参数\n",
    "# todo 调参\n",
    "learning_rate = 0.01\n",
    "numb_epochs = 30\n",
    "batch_size = 32\n",
    "weight_decay = 0.05 # 上一次为0.1，过拟合，train_loss=0.5+, test_loss=2.1+\n",
    "device = try_device()"
   ],
   "id": "1ab68d8778051df3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.276331Z",
     "start_time": "2024-05-10T07:34:36.261307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 分层K折\n",
    "num_folds = 6\n",
    "k_fold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)  # 随机种子固定,保证每次生成的都一样"
   ],
   "id": "6928fedfff3546d5",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:36.291855Z",
     "start_time": "2024-05-10T07:34:36.278336Z"
    }
   },
   "cell_type": "code",
   "source": "k_fold",
   "id": "22a2e4525dc134d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=6, random_state=42, shuffle=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:37.184826Z",
     "start_time": "2024-05-10T07:34:36.292854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 实例化模型\n",
    "model = CNNBiLSTMModel()\n",
    "\n",
    "# 初始化模型参数\n",
    "model.apply(init_weights)\n",
    "\n",
    "# 模型传入device\n",
    "print('Training on', device)\n",
    "model.to(device)\n",
    "\n",
    "# 设置优化器和损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, min_lr=1e-5, factor=0.9, patience=5, verbose=True)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ],
   "id": "1e734ea70efc4b65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:37.246704Z",
     "start_time": "2024-05-10T07:34:37.185847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练数据加载\n",
    "train_data = data.copy()    # 不改变源数据\n",
    "print(data.shape)\n",
    "print(train_data.shape)\n",
    "# 下面两项操作都不会改变train_data数据,在模型中不需要改变\n",
    "labels = train_data['Class']\n",
    "class_names = list(OrderedDict.fromkeys(labels.to_list())) # 获取列名\n",
    "print(class_names)\n",
    "print(f'labels.shape = {labels.shape}')\n",
    "print(f'labels.dtype = {labels.dtype}')\n",
    "print(train_data.shape)\n",
    "features  = train_data.drop(['Class'], axis=1, inplace=False)\n",
    "print(features.shape)"
   ],
   "id": "ed01039e1d59ef1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148517, 123)\n",
      "(148517, 123)\n",
      "['Normal', 'Dos', 'R2L', 'Probe', 'U2R']\n",
      "labels.shape = (148517,)\n",
      "labels.dtype = object\n",
      "(148517, 123)\n",
      "(148517, 122)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:37.262228Z",
     "start_time": "2024-05-10T07:34:37.247705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始化存储结构，每个fold的每个epoch的数据都会被存储\n",
    "fold_metrics = {\n",
    "    # train\n",
    "    'train_loss': [[] for _ in range(numb_epochs)],\n",
    "    'train_accuracy': [[] for _ in range(numb_epochs)], # accuracy两种方法没用区别\n",
    "    # 加权平均指标\n",
    "    'train_precision_weighted': [[] for _ in range(numb_epochs)],\n",
    "    'train_recall_weighted': [[] for _ in range(numb_epochs)],\n",
    "    'train_f1_weighted': [[] for _ in range(numb_epochs)],\n",
    "    # 微平均法指标\n",
    "    'train_precision_micro': [[] for _ in range(numb_epochs)],\n",
    "    'train_recall_micro': [[] for _ in range(numb_epochs)],\n",
    "    'train_f1_micro': [[] for _ in range(numb_epochs)],\n",
    "    \n",
    "    # val \n",
    "    'val_loss': [[] for _ in range(numb_epochs)],\n",
    "    'val_accuracy': [[] for _ in range(numb_epochs)],   # accuracy两种方法没用区别\n",
    "    # 加权平均指标\n",
    "    'val_precision_weighted': [[] for _ in range(numb_epochs)],\n",
    "    'val_recall_weighted': [[] for _ in range(numb_epochs)],\n",
    "    'val_f1_weighted': [[] for _ in range(numb_epochs)],\n",
    "    # 微平均法指标\n",
    "    'val_precision_micro': [[] for _ in range(numb_epochs)],\n",
    "    'val_recall_micro': [[] for _ in range(numb_epochs)],\n",
    "    'val_f1_micro': [[] for _ in range(numb_epochs)],\n",
    "}\n",
    "# 初始化用于存储所有混淆矩阵的列表\n",
    "all_conf_matrices = []"
   ],
   "id": "97015078219dfbda",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:34:37.277264Z",
     "start_time": "2024-05-10T07:34:37.264230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 绘制混淆矩阵\n",
    "def plot_confusion_matrix(conf_matrix, class_names, figsize=(10, 8), title='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    绘制混淆矩阵的函数。\n",
    "\n",
    "    参数:\n",
    "    conf_matrix (array-like): 混淆矩阵的数组。\n",
    "    class_names (list): 类别名称的列表。\n",
    "    figsize (tuple): 图的大小，默认为(10, 8)。\n",
    "    title (str): 图的标题，默认为'Confusion Matrix'。\n",
    "    \"\"\"\n",
    "    # class_names = ['Normal', 'Dos', 'R2L', 'Probe', 'U2R']\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()  # 调整布局以防止边缘被切割\n",
    "    plt.show()\n",
    "\n",
    "# 使用示例：\n",
    "# 假设combined_conf_matrix是合并后的混淆矩阵，class_names是类别名称列表\n",
    "# plot_confusion_matrix(combined_conf_matrix, class_names)"
   ],
   "id": "f6a3658b8356676e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-10T07:34:37.279266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 完整训练\n",
    "for epoch in range(numb_epochs):\n",
    "    start_time = time.time()\n",
    "    print(f'Epoch {epoch + 1}/{numb_epochs}')\n",
    "    # 全部K折完算一次epoch, 共需要经历numb_epochs次迭代\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "        fold = 0    # fold计数器\n",
    "        for (train_index, val_index) in k_fold.split(features, labels):\n",
    "            fold += 1   \n",
    "            print(f'Fold {fold}/{num_folds}')   # 当前为第fold次K折        \n",
    "            \n",
    "            # 根据K折设置训练集和验证集\n",
    "            train_data, val_data = features.iloc[train_index], features.iloc[val_index]\n",
    "            train_labels, val_labels = labels.iloc[train_index], labels.iloc[val_index]\n",
    "            # 只在第一次fold中打印shape\n",
    "            if fold == 1:\n",
    "                print(f'train_data.shape = {train_data.shape}, val_data.shape = {val_data.shape}')\n",
    "                \n",
    "            # 设置Data_Loder\n",
    "            train_loader = loop_data_loder(train_data, train_labels, batch_size)\n",
    "            val_loader = loop_data_loder(val_data, val_labels, batch_size)\n",
    "            \n",
    "            # 初始化fold统计数据\n",
    "            fold_train_loss = 0.0\n",
    "            fold_train_correct = 0\n",
    "            fold_train_total = 0\n",
    "            fold_val_loss = 0.0\n",
    "            fold_val_correct = 0\n",
    "            fold_val_total = 0\n",
    "            fold_train_preds = []\n",
    "            fold_train_targets = []\n",
    "            fold_val_preds = []\n",
    "            fold_val_targets = []\n",
    "            \n",
    "            '''在当前fold训练集上训练模型'''\n",
    "            model.train()\n",
    "            for train_batch, train_label_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                train_batch, train_label_batch = train_batch.to(device), train_label_batch.to(device)\n",
    "                \n",
    "                outputs = model(train_batch)\n",
    "                loss = loss_fn(outputs, train_label_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                fold_train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                fold_train_total += train_label_batch.size(0)\n",
    "                fold_train_correct += (predicted == train_label_batch).sum().item()\n",
    "                fold_train_preds.extend(predicted.view(-1).cpu().numpy())\n",
    "                fold_train_targets.extend(train_label_batch.cpu().numpy())\n",
    "            \n",
    "            # 计算训练集上的统计数据\n",
    "            train_loss = fold_train_loss / len(train_loader)\n",
    "            train_accuracy = fold_train_correct / fold_train_total\n",
    "            # 加权平均法计算precision，recall，F1-score\n",
    "            train_precision_weighted = precision_score(fold_train_targets, fold_train_preds, average='weighted', zero_division=0)\n",
    "            train_recall_weighted = recall_score(fold_train_targets, fold_train_preds, average='weighted', zero_division=0)\n",
    "            train_f1_weighted = f1_score(fold_train_targets, fold_train_preds, average='weighted', zero_division=0)\n",
    "            # 微平均法计算precision，recall，F1-score\n",
    "            train_precision_micro = precision_score(fold_val_targets, fold_val_preds, average='micro', zero_division=0)\n",
    "            train_recall_micro = recall_score(fold_val_targets, fold_val_preds, average='micro', zero_division=0)\n",
    "            train_f1_micro = f1_score(fold_val_targets, fold_val_preds, average='micro', zero_division=0)\n",
    "            \n",
    "            '''在当前fold验证集上评估模型'''\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_batch, val_label_batch in val_loader:\n",
    "                    val_batch, val_label_batch = val_batch.to(device), val_label_batch.to(device)\n",
    "                    outputs = model(val_batch)\n",
    "                    loss = loss_fn(outputs, val_label_batch)\n",
    "                    \n",
    "                    fold_val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    fold_val_total += val_label_batch.size(0)\n",
    "                    fold_val_correct += (predicted == val_label_batch).sum().item()\n",
    "                    fold_val_preds.extend(predicted.view(-1).cpu().numpy())\n",
    "                    fold_val_targets.extend(val_label_batch.cpu().numpy())\n",
    "            \n",
    "            '''\n",
    "            # 在每个fold后更新学习率, 如果你想更频繁地调整学习率，可以在每个fold后调整。\n",
    "            scheduler.step(fold_val_loss) # 已在全部fold结束后添加\n",
    "            '''\n",
    "            \n",
    "            # 计算并存储当前fold的混淆矩阵\n",
    "            fold_conf_matrix = confusion_matrix(fold_val_targets, fold_val_preds)\n",
    "            all_conf_matrices.append(fold_conf_matrix)\n",
    "            \n",
    "            # 计算验证集上的统计数据\n",
    "            '''\n",
    "            # accuracy，pre，recall，F1-score使用微平均法计算\n",
    "            # 对于每次的交叉验证，累积每个类别的真正例（TP）、假正例（FP）和假负例（FN）。\n",
    "            # 使用累积的TP、FP和FN来计算整体的precision、recall和F1分数：\n",
    "            '''\n",
    "            val_loss = fold_val_loss / len(val_loader)\n",
    "            val_accuracy = fold_val_correct / fold_val_total\n",
    "            # 加权平均法计算precision，recall，F1-score\n",
    "            val_precision_weighted = precision_score(fold_val_targets, fold_val_preds, average='weighted', zero_division=0)\n",
    "            val_recall_weighted = recall_score(fold_val_targets, fold_val_preds, average='weighted', zero_division=0)\n",
    "            val_f1_weighted = f1_score(fold_val_targets, fold_val_preds, average='weighted', zero_division=0)\n",
    "            # 微平均法计算precision，recall，F1-score\n",
    "            val_precision_micro = precision_score(fold_val_targets, fold_val_preds, average='micro', zero_division=0)\n",
    "            val_recall_micro = recall_score(fold_val_targets, fold_val_preds, average='micro', zero_division=0)\n",
    "            val_f1_micro = f1_score(fold_val_targets, fold_val_preds, average='micro', zero_division=0)\n",
    "    \n",
    "            # 将当前fold的统计数据添加到fold_metrics中\n",
    "            for i in range (1):     # 循环没用，单纯想折叠大段代码\n",
    "                # train\n",
    "                fold_metrics['train_loss'][epoch].append(train_loss)\n",
    "                fold_metrics['train_accuracy'][epoch].append(train_accuracy)\n",
    "                # 添加加权平均数据\n",
    "                fold_metrics['train_precision_weighted'][epoch].append(train_precision_weighted)\n",
    "                fold_metrics['train_recall_weighted'][epoch].append(train_recall_weighted)\n",
    "                fold_metrics['train_f1_weighted'][epoch].append(train_f1_weighted)\n",
    "                # 添加微平均法数据\n",
    "                fold_metrics['train_precision_micro'][epoch].append(train_precision_micro)\n",
    "                fold_metrics['train_recall_micro'][epoch].append(train_recall_micro)\n",
    "                fold_metrics['train_f1_micro'][epoch].append(train_f1_micro)\n",
    "                \n",
    "                # val\n",
    "                fold_metrics['val_loss'][epoch].append(val_loss)\n",
    "                fold_metrics['val_accuracy'][epoch].append(val_accuracy)\n",
    "                # 加权平均指标\n",
    "                fold_metrics['val_precision_weighted'][epoch].append(val_precision_weighted)\n",
    "                fold_metrics['val_recall_weighted'][epoch].append(val_recall_weighted)\n",
    "                fold_metrics['val_f1_weighted'][epoch].append(val_f1_weighted)\n",
    "                # 微平均法指标\n",
    "                fold_metrics['val_precision_micro'][epoch].append(val_precision_micro)\n",
    "                fold_metrics['val_recall_micro'][epoch].append(val_recall_micro)\n",
    "                fold_metrics['val_f1_micro'][epoch].append(val_f1_micro)\n",
    "    \n",
    "        '''如果你的模型在不同的folds上表现差异很大，使用所有folds的平均损失可能更合适。'''\n",
    "        # 在所有folds完成后，更新learning_rate\n",
    "        val_loss_avg = sum(fold_metrics['val_loss'][epoch]) / num_folds\n",
    "        scheduler.step(val_loss_avg)\n",
    "        \n",
    "        # 打印epoch的平均统计数据（如果需要）\n",
    "        # 循环没用，单纯想折叠大段代码\n",
    "        for i in range (1):\n",
    "            print(f'Epoch {epoch + 1} : ')\n",
    "            print(f'Average Training Loss: {np.mean(fold_metrics[\"train_loss\"][epoch]):.4f}, ')\n",
    "            print(f'Average Training Accuracy: {np.mean(fold_metrics[\"train_accuracy\"][epoch]):.4f}, ')\n",
    "            print(f'Average Validation Loss: {np.mean(fold_metrics[\"val_loss\"][epoch]):.4f}, ')\n",
    "            print(f'Average Validation Accuracy: {np.mean(fold_metrics[\"val_accuracy\"][epoch]):.4f}, ')\n",
    "    \n",
    "    print(prof.key_averages().table(sort_by='cpu_time_total', row_limit=10))    \n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f'Epoch{epoch}/{numb_epochs} took {epoch_time:.2f} seconds')\n",
    "    print('--------------------------------------\\n')"
   ],
   "id": "3666512fce644da8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Fold 1/6\n",
      "train_data.shape = (123764, 122), val_data.shape = (24753, 122)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# 所有epoch和fold完成后，合并混淆矩阵\n",
    "combined_conf_matrix = np.sum(all_conf_matrices, axis=0)\n",
    "\n",
    "# 绘制合并后的混淆矩阵\n",
    "plot_confusion_matrix(combined_conf_matrix, class_names)"
   ],
   "id": "c97b138bf78e861d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# val_accuracy \n",
    "# 第一张图：每个fold的train_accuracy和模型总体的val_accuracy随epoch变化的曲线\n",
    "def plot_fold_train_accuracies(fold_metrics, numb_epochs):\n",
    "    epochs = range(1, numb_epochs + 1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # for fold in range(num_folds):\n",
    "    #     plt.plot(epochs, [fold_metrics['train_accuracy'][epoch][fold] for epoch in range(numb_epochs)], label=f'Fold {fold + 1}')\n",
    "    # \n",
    "    # 计算并绘制模型总体的val_accuracy\n",
    "    overall_train_accuracy = [np.mean([fold_metrics['val_accuracy'][epoch][fold] for fold in range(num_folds)]) for epoch in range(numb_epochs)]\n",
    "    plt.plot(epochs, overall_train_accuracy, label='Overall Val Accuracy', color='black', linewidth=2, linestyle='--')\n",
    "    \n",
    "    plt.title('Val Accuracy per Fold over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Val Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ],
   "id": "35e58af6d2653d1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# 第二张图：模型总体的train_loss, val_loss随epoch变化的曲线\n",
    "def plot_overall_metrics(fold_metrics, numb_epochs):\n",
    "    epochs = range(1, numb_epochs + 1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # # 绘制模型总体的train_accuracy和val_accuracy\n",
    "    # overall_train_accuracy = [np.mean(fold_metrics['train_accuracy'][epoch]) for epoch in range(numb_epochs)]\n",
    "    # overall_val_accuracy = [np.mean(fold_metrics['val_accuracy'][epoch]) for epoch in range(numb_epochs)]\n",
    "    # plt.plot(epochs, overall_train_accuracy, label='Overall Train Accuracy', marker='o')\n",
    "    # plt.plot(epochs, overall_val_accuracy, label='Overall Val Accuracy', marker='v')\n",
    "    \n",
    "    # 绘制模型总体的train_loss和val_loss\n",
    "    overall_train_loss = [np.mean(fold_metrics['train_loss'][epoch]) for epoch in range(numb_epochs)]\n",
    "    overall_val_loss = [np.mean(fold_metrics['val_loss'][epoch]) for epoch in range(numb_epochs)]\n",
    "    plt.plot(epochs, overall_train_loss, label='Overall Train Loss', marker='s')\n",
    "    plt.plot(epochs, overall_val_loss, label='Overall Val Loss', marker='*')\n",
    "    \n",
    "    plt.title('Overall Training/Validation Metrics over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ],
   "id": "9ad5ce41c5e5e38d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# 第三张图：模型的accuracy, recall, precision, f1分数随epoch变化的曲线\n",
    "def plot_performance_metrics(fold_metrics, numb_epochs):\n",
    "    epochs = range(1, numb_epochs + 1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 计算模型总体的performance metrics\n",
    "    overall_accuracy = [np.mean(fold_metrics['val_accuracy'][epoch]) for epoch in range(numb_epochs)]\n",
    "    overall_recall_weighted = [np.mean(fold_metrics['val_recall_weighted'][epoch]) for epoch in range(numb_epochs)]\n",
    "    overall_precision_weighted = [np.mean(fold_metrics['val_precision_weighted'][epoch]) for epoch in range(numb_epochs)]\n",
    "    overall_f1_weighted = [np.mean(fold_metrics['val_f1_weighted'][epoch]) for epoch in range(numb_epochs)]\n",
    "    overall_precision_micor = [np.mean(fold_metrics['val_recall_micro'][epoch]) for epoch in range(numb_epochs)]\n",
    "    overall_recall_micor = [np.mean(fold_metrics['val_recall_micro'][epoch]) for epoch in range(numb_epochs)]\n",
    "    overall_f1_micor = [np.mean(fold_metrics['val_precision_micro'][epoch]) for epoch in range(numb_epochs)]\n",
    "    \n",
    "    \n",
    "    # 绘制曲线\n",
    "    plt.plot(epochs, overall_accuracy, label='Accuracy_weighted', marker='x')\n",
    "    # weighted指标\n",
    "    plt.plot(epochs, overall_recall_weighted, label='Recall_weighted', marker='v')\n",
    "    plt.plot(epochs, overall_precision_weighted, label='Precision_weighted', marker='s')\n",
    "    plt.plot(epochs, overall_f1_weighted, label='F1 Score_weighted', marker='*')\n",
    "    # micor指标\n",
    "    plt.plot(epochs, overall_recall_micor, label='Recall_micro', marker='^')\n",
    "    plt.plot(epochs, overall_precision_micor, label='Precision_micro', marker='p')\n",
    "    plt.plot(epochs, overall_f1_micor, label='F1_micro', marker='^')\n",
    "    \n",
    "    \n",
    "    plt.title('Performance Metrics over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "1893c60b431efda1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# 每个fold的train_accuracy和模型总体的train_accuracy随epoch变化的曲线\n",
    "plot_fold_train_accuracies(fold_metrics, numb_epochs)"
   ],
   "id": "4530fad2b7039a28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# 模型总体的train_accuracy, train_loss, val_accuracy, val_loss随epoch变化的曲线\n",
    "plot_overall_metrics(fold_metrics, numb_epochs)"
   ],
   "id": "d6753cc50a1ffbba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# 模型的accuracy, recall, precision, f1分数随epoch变化的曲线\n",
    "plot_performance_metrics(fold_metrics, numb_epochs)"
   ],
   "id": "41aec6526f060da9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
